{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07. Molecules CG Mapping \n",
    "\n",
    "In this tutorial, we show how to generate a CG mapping matrix for a molecule given a bead distribution. The trajectory and topology file come from a AA simulation done in gromacs (see `Molecules_CG_Mapping` folder). The protein is FF (diphenylalanine) and the solvent is a mixture of water and methanol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable GPU\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "import hoomd, hoomd.htf as htf, hoomd.md\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import MDAnalysis as mda\n",
    "from os import path\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt,matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mgholiza/.conda/envs/hoomd-tf2/lib/python3.7/site-packages/MDAnalysis/core/universe.py:171: UserWarning: No coordinate reader found for Molecules_CG_Mapping/nvt_prod.tpr. Skipping this file.\n",
      "  'this file.'.format(filename))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8224383  0.05918723 0.05918723 0.05918723 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.        ]\n",
      " [0.         0.         0.         0.         0.44409524 0.03726984\n",
      "  0.44409524 0.03726984 0.03726984 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.15577257 0.15577257 0.01307291\n",
      "  0.15577257 0.01307291 0.15577257 0.01307291 0.15577257 0.01307291\n",
      "  0.15577257 0.01307291 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.42880501 0.57119499 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.93286579 0.06713421\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.44409524 0.03726984 0.44409524 0.03726984 0.03726984 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.15577257\n",
      "  0.15577257 0.01307291 0.15577257 0.01307291 0.15577257 0.01307291\n",
      "  0.15577257 0.01307291 0.15577257 0.01307291 0.         0.\n",
      "  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.27291648 0.36354176\n",
      "  0.36354176]]\n"
     ]
    }
   ],
   "source": [
    "# Loading inputs\n",
    "TPR = 'Molecules_CG_Mapping/nvt_prod.tpr'\n",
    "tpr = mda.Universe(TPR)\n",
    "TRAJECTORY = 'Molecules_CG_Mapping/traj.trr'\n",
    "u = mda.Universe(TPR, TRAJECTORY)\n",
    "\n",
    "# Generating Mapping Matrix for FF\n",
    "protein_FF = u.select_atoms(\"resname PHE and resid 0:1\")\n",
    "Beads_distribution = [['N','H1','H2','H3'],\n",
    "                     ['CA','HA','CB','HB1','HB2'],\n",
    "                     ['CG','CD1','HD1','CD2','HD2','CE1','HE1','CE2','HE2','CZ','HZ'],\n",
    "                     ['C','O'],\n",
    "                     ['N','H'],\n",
    "                     ['CA','HA','CB','HB1','HB2'],\n",
    "                     ['CG','CD1','HD1','CD2','HD2','CE1','HE1','CE2','HE2','CZ','HZ'],\n",
    "                     ['C','O1','O2']]\n",
    "mapping_FF = htf.matrix_mapping(protein_FF,Beads_distribution)\n",
    "print (mapping_FF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.88809574 0.05595213 0.05595213]]\n"
     ]
    }
   ],
   "source": [
    "# Generating Mapping Matrix for Water\n",
    "water = u.select_atoms(\"resname SOL and resid 500\")\n",
    "Beads_distribution = [['OW','HW1','HW2']]\n",
    "mapping_water = htf.matrix_mapping(water,Beads_distribution)             \n",
    "print (mapping_water)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.37484707 0.03145832 0.03145832 0.03145832 0.49931966 0.03145832]]\n"
     ]
    }
   ],
   "source": [
    "# Generating Mapping Matrix for Methanol\n",
    "methanol = u.select_atoms(\"resname MET and resid 11665 \")\n",
    "Beads_distribution_methanol = [['C','H','H','H','OA','HO']]\n",
    "mapping_methanol = htf.matrix_mapping(methanol,Beads_distribution_methanol)             \n",
    "print (mapping_methanol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the segment id of each molecule in topology\n",
    "_,idx = np.unique(u.select_atoms('all').segids,return_index=True)\n",
    "seg_id_list = u.select_atoms('all').segids[np.sort(idx)].tolist()\n",
    "\n",
    "# Getting the list of every molecule type name in topology\n",
    "_,idx = np.unique(u.atoms.resnames,return_index=True)\n",
    "resname_list = u.atoms.resnames[np.sort(idx)].tolist()\n",
    "\n",
    "# Getting list of atoms in each type of molecule\n",
    "atoms_in_molecule_list = [protein_FF.names,\n",
    "                          water.names,\n",
    "                          methanol.names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160\n"
     ]
    }
   ],
   "source": [
    "atoms_in_molecule_list = [protein_FF.names]\n",
    "molecule_mapping_index = htf.find_molecules_from_topology(u,atoms_in_molecule_list, selection = \"resname PHE\")\n",
    "molecule_mapping = mapping_FF\n",
    "\n",
    "# get number of atoms\n",
    "N = sum([len(m) for m in molecule_mapping_index])\n",
    "# get number of molecules\n",
    "M = len(molecule_mapping_index)\n",
    "# get number of beads\n",
    "B = molecule_mapping.shape[0]\n",
    "\n",
    "#create a mass-weighted (M * bead_number) x N mapping operator \n",
    "cg_mapping = htf.sparse_mapping([molecule_mapping for _ in molecule_mapping_index], \n",
    "                                molecule_mapping_index)\n",
    "assert cg_mapping.shape == (M * B, N)\n",
    "print (M*B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model graph\n",
    "\n",
    "We build an LJ potential with unknown, trainable parameters (`epsilon`, `sigma`) which start out at 0.9 and 1.1. We then obtain forces from our potential and the simulation. Force matching is used to modify the LJ potential until the forces agree. We use Keras layers to implement the trainable parameters. We'll make our starting parameters $\\epsilon=1.2$ and $\\sigma=0.9$. The goal is train them to reach $\\sigma, \\epsilon = 1.0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LJLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, sig, eps):\n",
    "        super().__init__(self, name='lj')\n",
    "        self.start = [sig, eps]\n",
    "        self.w = self.add_weight(\n",
    "            shape=[2],\n",
    "            initializer=tf.constant_initializer([sig, eps]),\n",
    "            constraint=tf.keras.constraints.NonNeg())\n",
    "\n",
    "    def call(self, r):\n",
    "        r6 = tf.math.divide_no_nan(self.w[1]**6, r**6)\n",
    "        energy = self.w[0] * 4.0 * (r6**2 - r6)\n",
    "        # divide by 2 to remove double count\n",
    "        return energy / 2.\n",
    "    \n",
    "class TrainableLJ(htf.SimModel):\n",
    "    def setup(self,cg_mapping, rcut, CG_NN):\n",
    "        self.lj = LJLayer(0.9, 1.2)\n",
    "        self.rcut = rcut\n",
    "        self.cg_mapping = cg_mapping\n",
    "        self.CG_NN = CG_NN\n",
    "\n",
    "    def compute(self, nlist, positions, box, cg_mapping):\n",
    "        # calculate the center of mass of a CG bead\n",
    "        box_size = [box[0,0],box[0,0],box[0,0]]\n",
    "        print('Box size is ', box_size)\n",
    "        mapped_pos = htf.center_of_mass(positions[:,:3], self.cg_mapping, box_size)\n",
    "        mapped_nlist = htf.compute_nlist(mapped_pos, self.rcut, self.CG_NN, box_size, True)\n",
    "        # get r\n",
    "        r = htf.safe_norm(tensor=nlist[:, :, :3], axis=2)\n",
    "        p_energy = self.lj(r)\n",
    "        energy = tf.reduce_sum(input_tensor=p_energy, axis=1)\n",
    "        forces = htf.compute_nlist_forces(nlist, energy)\n",
    "        # get mapped_r\n",
    "        mapped_r = htf.safe_norm(tensor=mapped_nlist[:, :, :3], axis=2)\n",
    "        mapped_p_energy = self.lj(mapped_r)\n",
    "        mapped_energy = tf.reduce_sum(input_tensor=mapped_p_energy, axis=1)\n",
    "        mapped_forces = htf.compute_nlist_forces(mapped_nlist, mapped_energy)\n",
    "        print ('mapped_forces is ', mapped_forces)\n",
    "\n",
    "        return forces, self.lj.w, energy, mapped_forces, mapped_energy, mapped_pos, mapped_nlist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cut = 50\n",
    "model = TrainableLJ(128,cg_mapping = cg_mapping, rcut = r_cut, CG_NN = 128)\n",
    "model.compile('Adam', loss=['MeanSquaredError', None, None, None, None, None, None])\n",
    "# tfcompute = htf.tfcompute(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Universe with 46502 atoms>\n",
      "[78.9851 78.9851 78.9851 90.     90.     90.    ]\n"
     ]
    }
   ],
   "source": [
    "print(u)\n",
    "modif_u = mda.Merge(u.select_atoms('resname PHE'))\n",
    "print(u.dimensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run from trajectory\n",
    "\n",
    "We load the trajectory with `MDAnalysis` and then call the `iter_from_trajectory` command. It runs over the trajectory computing the graph and constructs neighborlists according to the r_cut. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "universe <Universe with 860 atoms>\n",
      "Box size is  [<tf.Tensor 'strided_slice:0' shape=() dtype=float32>, <tf.Tensor 'strided_slice_1:0' shape=() dtype=float32>, <tf.Tensor 'strided_slice_2:0' shape=() dtype=float32>]\n",
      "mapped_forces is  Tensor(\"concat_3:0\", shape=(160, 4), dtype=float32)\n",
      "< Timestep 0 with unit cell dimensions [0. 0. 0. 0. 0. 0.] >\n",
      "inputs type <class 'list'> inputs shape (3, 3)\n",
      "labels type <class 'tensorflow.python.framework.ops.EagerTensor'> labels shape (160, 4)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " Cannot multiply A and B because inner dimension does not match: 860 vs. 160.  Did you forget a transpose?  Dimensions of A: [160, 860).  Dimensions of B: [160,3]\n\t [[{{node htf-model/StatefulPartitionedCall/SparseTensorDenseMatMul/SparseTensorDenseMatMul}}]] [Op:__inference_train_function_2826]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-eaf4263fd006>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#     loss = model.train_on_batch(model_inputs, model_inputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#     box_size = htf.box_size(box)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/hoomd-tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   1693\u001b[0m                                                     class_weight)\n\u001b[1;32m   1694\u001b[0m       \u001b[0mtrain_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/hoomd-tf2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/hoomd-tf2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/hoomd-tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/hoomd-tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/hoomd-tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/hoomd-tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.conda/envs/hoomd-tf2/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  Cannot multiply A and B because inner dimension does not match: 860 vs. 160.  Did you forget a transpose?  Dimensions of A: [160, 860).  Dimensions of B: [160,3]\n\t [[{{node htf-model/StatefulPartitionedCall/SparseTensorDenseMatMul/SparseTensorDenseMatMul}}]] [Op:__inference_train_function_2826]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "Total_energy = []\n",
    "Total_mapped_energy = []\n",
    "for inputs, ts in htf.iter_from_trajectory(128, u,selection='resname PHE', r_cut=r_cut,period =10):\n",
    "#     aa_pos = inputs[1].astype('float32')\n",
    "#     box = inputs[2].astype('float32')\n",
    "#     box_size = [box[0,0],box[0,0],box[0,0]]\n",
    "    forces, lj_w, energy, mapped_forces, mapped_energy, mapped_pos, mapped_nlist = model(inputs)\n",
    "    cg_type = tf.zeros((mapped_nlist.shape[0],1))\n",
    "    mapped_pos_with_type = tf.concat([mapped_pos, cg_type], axis =1)\n",
    "    model_inputs = [mapped_nlist, mapped_pos_with_type] + inputs[2:] # get box,  other items\n",
    "    labels = mapped_forces\n",
    "#     print ([type(a) for a in model_inputs])\n",
    "    print (ts)\n",
    "    print('inputs type', type(model_inputs), 'inputs shape', model_inputs[2].shape)\n",
    "    print('labels type', type(labels), 'labels shape', labels.shape)\n",
    "    Total_energy.append(np.sum(energy))\n",
    "    Total_mapped_energy.append(tf.reduce_sum(mapped_energy))\n",
    "#     loss = model.train_on_batch(model_inputs, model_inputs)\n",
    "    \n",
    "    loss = model.train_on_batch(model_inputs,  labels)\n",
    "\n",
    "#     box_size = htf.box_size(box)\n",
    "#     mapped_pos = htf.center_of_mass(aa_pos, cg_mapping, box_size)\n",
    "    # create the mapped neighbor list\n",
    "#     mapped_nlist = htf.compute_nlist(mapped_pos, r_cut, CG_NN, box_size, True)\n",
    "#     mapped_forces = htf.compute_nlist_forces(mapped_nlist, energy)\n",
    "print (Total_energy)\n",
    "plt.plot(Total_energy,label ='energy')\n",
    "# plt.plot(Total_mapped_energy,label='mapped energy')\n",
    "plt.legend()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LJLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, sig, eps):\n",
    "        super().__init__(self, name='lj')\n",
    "        self.start = [sig, eps]\n",
    "        self.w = self.add_weight(\n",
    "            shape=[2],\n",
    "            initializer=tf.constant_initializer([sig, eps]),\n",
    "            constraint=tf.keras.constraints.NonNeg())\n",
    "\n",
    "    def call(self, r):\n",
    "        r6 = tf.math.divide_no_nan(self.w[1]**6, r**6)\n",
    "        energy = self.w[0] * 4.0 * (r6**2 - r6)\n",
    "        # divide by 2 to remove double count\n",
    "        return energy / 2.\n",
    "    \n",
    "class TrainableLJ(htf.SimModel):\n",
    "    def setup(self,cg_mapping, rcut, CG_NN):\n",
    "        self.lj = LJLayer(0.9, 1.2)\n",
    "        self.rcut = rcut\n",
    "        self.cg_mapping = cg_mapping\n",
    "        self.CG_NN = CG_NN\n",
    "\n",
    "    def compute(self, mapped_nlist):\n",
    "        # calculate the center of mass of a CG bead\n",
    "        # get r\n",
    "#         r = htf.safe_norm(tensor=nlist[:, :, :3], axis=2)\n",
    "#         p_energy = self.lj(r)\n",
    "#         energy = tf.reduce_sum(input_tensor=p_energy, axis=1)\n",
    "#         forces = htf.compute_nlist_forces(nlist, energy)\n",
    "        # get mapped_r\n",
    "\n",
    "        mapped_r = htf.safe_norm(tensor=mapped_nlist[:, :, :3], axis=2)\n",
    "        mapped_p_energy = self.lj(mapped_r)\n",
    "        mapped_energy = tf.reduce_sum(input_tensor=mapped_p_energy, axis=1)\n",
    "#         print ('mapped_energy is ', mapped_energy)\n",
    "        mapped_forces = htf.compute_nlist_forces(mapped_nlist, mapped_energy)\n",
    "#         print ('mapped_forces is ', mapped_forces)\n",
    "\n",
    "        return  mapped_forces, mapped_energy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "universe <Universe with 860 atoms>\n",
      "< Timestep 0 with unit cell dimensions [0. 0. 0. 0. 0. 0.] >\n",
      "[3.4423898079425556e-16, 3.4423898079425556e-16]\n"
     ]
    }
   ],
   "source": [
    "r_cut = 2\n",
    "CG_NN = 128\n",
    "model = TrainableLJ(128,cg_mapping = cg_mapping, rcut = r_cut, CG_NN = CG_NN)\n",
    "model.compile('Adam', loss=['MeanSquaredError', None])\n",
    "Total_energy = []\n",
    "Total_mapped_energy = []\n",
    "losses = []\n",
    "for inputs, ts in htf.iter_farom_trajectory(128, u,selection='resname PHE', r_cut=r_cut,period =1):\n",
    "#     aa_pos = inputs[1].astype('float32')\n",
    "    print(ts)\n",
    "    nlist = inputs[0]\n",
    "    positions = inputs[1]\n",
    "    box = inputs[2].astype('float32')\n",
    "    box_size = tf.constant([box[0,0],box[0,0],box[0,0]])\n",
    "    mapped_pos = htf.center_of_mass(positions[:,:3], cg_mapping, box_size)\n",
    "    mapped_nlist = htf.compute_nlist(mapped_pos, r_cut, CG_NN, box_size, True)\n",
    "    cg_type = tf.zeros((mapped_nlist.shape[0],1))\n",
    "    mapped_pos_with_type = tf.concat([mapped_pos, cg_type], axis =1)\n",
    "    print('shape mapped_nlist = ', mapped_nlist.shape)\n",
    "    print('shape mapped_pos = ', mapped_pos.shape)\n",
    "    mapped_forces, mapped_energy = model(mapped_nlist[tf.newaxis, ...])\n",
    "    model_inputs = [mapped_nlist, mapped_pos_with_type, box_size] + inputs[3:]\n",
    "    labels = mapped_forces\n",
    "    loss = model.train_on_batch(model_inputs,  labels)\n",
    "    print(loss)\n",
    "#     print(loss)\n",
    "#     losses.append(loss)\n",
    "#     forces, lj_w, energy, mapped_forces, mapped_energy, mapped_pos, mapped_nlist = model(inputs)\n",
    "#     cg_type = tf.zeros((mapped_nlist.shape[0],1))\n",
    "#     mapped_pos_with_type = tf.concat([mapped_pos, cg_type], axis =1)\n",
    "#     model_inputs = [mapped_nlist, mapped_pos_with_type] + inputs[2:] # get box,  other items\n",
    "#     labels = mapped_forces\n",
    "# #     print ([type(a) for a in model_inputs])\n",
    "#     print (ts)\n",
    "#     print('inputs type', type(model_inputs), 'inputs shape', model_inputs[2].shape)\n",
    "#     print('labels type', type(labels), 'labels shape', labels.shape)\n",
    "#     Total_energy.append(np.sum(energy))\n",
    "#     Total_mapped_energy.append(tf.reduce_sum(mapped_energy))\n",
    "# #     loss = model.train_on_batch(model_inputs, model_inputs)\n",
    "    \n",
    "#     loss = model.train_on_batch(model_inputs,  labels)\n",
    "\n",
    "# #     box_size = htf.box_size(box)\n",
    "# #     mapped_pos = htf.center_of_mass(aa_pos, cg_mapping, box_size)\n",
    "#     # create the mapped neighbor list\n",
    "# #     mapped_nlist = htf.compute_nlist(mapped_pos, r_cut, CG_NN, box_size, True)\n",
    "# #     mapped_forces = htf.compute_nlist_forces(mapped_nlist, energy)\n",
    "# print (Total_energy)\n",
    "# plt.plot(Total_energy,label ='energy')\n",
    "# # plt.plot(Total_mapped_energy,label='mapped energy')\n",
    "# plt.legend()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute(self, nlist, positions, box, cg_mapping):\n",
    "#         # calculate the center of mass of a CG bead\n",
    "#         box_size = [box[0,0],box[0,0],box[0,0]]\n",
    "#         mapped_pos = htf.center_of_mass(positions[:,:3], self.cg_mapping, box_size)\n",
    "#         mapped_nlist = htf.compute_nlist(mapped_pos, self.rcut, self.CG_NN, box_size, True)\n",
    "# #         rinv_6 = htf.nlist_rinv(mapped_nlist)**6\n",
    "# #         # closest neighbors have largest value in 1/r, take top\n",
    "# #         top_n = tf.sort(rinv, axis=1, direction='DESCENDING')[\n",
    "# #             :, :self.top_neighs]\n",
    "# #         # run through NN\n",
    "# #         x = self.dense1(top_n)\n",
    "# #         x = self.dense2(x)\n",
    "#         def energy_lj(nlist):\n",
    "#             rinv_6 = htf.nlist_rinv(nlist)**6\n",
    "#             p_energy = 4.0 / 2.0 * (rinv_6 * rinv_6 - rinv_6)\n",
    "#             e = tf.reduce_sum(p_energy, axis=1)\n",
    "#             return e\n",
    "#         energy = energy_lj(nlist)\n",
    "#         # get per-particle energy\n",
    "#         mapped_energy =  energy_lj(mapped_nlist)\n",
    "#         forces = htf.compute_nlist_forces(nlist, energy)\n",
    "#         mapped_forces = htf.compute_nlist_forces(mapped_nlist, mapped_energy)\n",
    "#         nlist_grad = tf.gradients(energy, nlist)[0]\n",
    "# #         tf.print (mapped_nlist)\n",
    "# #         nlist_grad = tf.gradients(energy, mapped_nlist)[0]\n",
    "# #         mapped_forces = htf.compute_nlist_forces(mapped_nlist, energy)\n",
    "#         return forces[:,:3], energy, mapped_forces[:,:3], mapped_energy, mapped_pos, mapped_nlist   \n",
    "    \n",
    "    \n",
    "# class TrajModel(htf.SimModel):\n",
    "#     def setup(self):\n",
    "#         self.avg_chrdf = tf.keras.metrics.MeanTensor()\n",
    "#         self.avg_ohrdf = tf.keras.metrics.MeanTensor()\n",
    "#     def compute(self, nlist, positions):                \n",
    "#         # pairwise energy. Double count -> divide by 2\n",
    "#         inv_r6 = htf.nlist_rinv(nlist)**6\n",
    "#         p_energy = 4.0 / 2.0 * (inv_r6 * inv_r6 - inv_r6)\n",
    "#         # sum over pairwise energy\n",
    "#         energy = tf.reduce_sum(p_energy, axis=1)\n",
    "#         # get forces\n",
    "#         forces = htf.compute_nlist_forces(nlist, energy)\n",
    "        \n",
    "#         # now get RDF\n",
    "#         # For reference, type indices in this case are: {C:0, H:1, N:2, O:3} \n",
    "#         # compute C-H RDF\n",
    "#         chrdf = htf.compute_rdf(\n",
    "#             nlist, [0, 15], positions[:, 3], \n",
    "#             nbins=20, type_i=0, type_j=1)\n",
    "#         # compute O-H RDF\n",
    "#         ohrdf = htf.compute_rdf(\n",
    "#             nlist,[0, 15],  positions[:, 3], \n",
    "#             nbins=20, type_i=3, type_j=1)\n",
    "#         # average the RDFs\n",
    "#         self.avg_chrdf.update_state(chrdf)\n",
    "#         self.avg_ohrdf.update_state(ohrdf)\n",
    "#         return forces\n",
    "    \n",
    "# # define model\n",
    "# class MappingModel(htf.SimModel):\n",
    "#     def setup(self, CG_NN, cg_mapping, rcut):\n",
    "#         self.CG_NN = CG_NN\n",
    "#         self.rcut = rcut\n",
    "#         self.cg_mapping = cg_mapping\n",
    "#         self.avg_cg_rdf = tf.keras.metrics.MeanTensor()\n",
    "#         self.avg_aa_rdf = tf.keras.metrics.MeanTensor()\n",
    "#     def compute(self, nlist, positions, box):\n",
    "#         # calculate the center of mass of a CG bead\n",
    "#         box_size = htf.box_size(box)\n",
    "#         mapped_pos = htf.center_of_mass(positions[:,:3], self.cg_mapping, box_size)\n",
    "#         # create the mapped neighbot list\n",
    "#         mapped_nlist = htf.compute_nlist(mapped_pos, self.rcut, self.CG_NN, box_size, True)\n",
    "#         # compute RDF for mapped and C-C in all-atom\n",
    "#         cg_rdf = htf.compute_rdf(mapped_nlist, [0.1,self.rcut])\n",
    "#         aa_rdf = htf.compute_rdf(nlist, [0.1,self.rcut], positions[:,3], type_i=3, type_j=3)\n",
    "#         self.avg_cg_rdf.update_state(cg_rdf)\n",
    "#         self.avg_aa_rdf.update_state(aa_rdf)\n",
    "#         return\n",
    "# # model = TrajModel(256)\n",
    "    \n",
    "# class NlistNN(htf.SimModel):\n",
    "#     def setup(self, dim, top_neighs):\n",
    "#         self.dense1 = tf.keras.layers.Layer(dim)\n",
    "#         self.dense2 = tf.keras.layers.Layer(dim)\n",
    "#         self.last = tf.keras.layers.Layer(1)\n",
    "#         self.top_neighs = top_neighs\n",
    "\n",
    "#     def compute(self, nlist, positions, box, sample_weight):\n",
    "#         rinv = htf.nlist_rinv(nlist)\n",
    "#         # closest neighbors have largest value in 1/r, take top\n",
    "#         top_n = tf.sort(rinv, axis=1, direction='DESCENDING')[\n",
    "#             :, :self.top_neighs]\n",
    "#         # run through NN\n",
    "#         x = self.dense1(top_n)\n",
    "#         x = self.dense2(x)\n",
    "#         pair_energy = self.last(x)\n",
    "#         # get per-particle energy\n",
    "#         energy = tf.reduce_sum(pair_energy, axis=1)\n",
    "#         forces = htf.compute_nlist_forces(nlist, energy)\n",
    "#         # don't output last column of forces, pairwise energy, since it's meaningless here\n",
    "#         return forces[:,:3], energy    \n",
    "    \n",
    "    \n",
    "# max_neighbor_est = 128\n",
    "# map_model = MappingModel(\n",
    "#     max_neighbor_est, \n",
    "#     CG_NN=max_neighbor_est, \n",
    "#     cg_mapping=cg_mapping, \n",
    "#     output_forces=False,\n",
    "#     rcut=10,\n",
    "#     check_nlist=True)\n",
    "# # print (u.trajectory.select_atoms('resname PHE'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(losses)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r_cut = 10\n",
    "# CG_NN=max_neighbor_est\n",
    "# for inputs, ts in htf.iter_from_trajectory(128, u,selection='resname PHE', r_cut=r_cut,period =20):\n",
    "#     print (ts)\n",
    "#     forces,energy = model(inputs)\n",
    "#     aa_pos = inputs[1].astype('float32')\n",
    "#     box = inputs[2].astype('float32')\n",
    "#     box_size = [box[0,0],box[0,0],box[0,0]]\n",
    "# #     box_size = htf.box_size(box)\n",
    "#     mapped_pos = htf.center_of_mass(aa_pos, cg_mapping, box_size)\n",
    "#     # create the mapped neighbor list\n",
    "#     mapped_nlist = htf.compute_nlist(mapped_pos, r_cut, CG_NN, box_size, True)\n",
    "# #     mapped_forces = htf.compute_nlist_forces(mapped_nlist, energy)\n",
    "# #     rinv = htf.nlist_rinv(mapped_nlist)\n",
    "# #     # closest neighbors have largest value in 1/r, take top\n",
    "# #     top_n = tf.sort(rinv, axis=1, direction='DESCENDING')[\n",
    "# #         :, :self.top_neighs]\n",
    "# #     # run through NN\n",
    "# #     x = self.dense1(top_n)\n",
    "# #     x = self.dense2(x)\n",
    "# #     pair_energy = self.last(x)\n",
    "    \n",
    "# #     mapped_forces = ...\n",
    "# #     mapped_nlist = htf.compute_nlist(mapped_pos, ...)\n",
    "# #     model_inputs = [mapped_pos, mapped_nlist] + inputs[2:] # get box,  other items\n",
    "# #     loss = my_model.train_on_batch(x = model_inputs, y = mapped_forces)\n",
    "# #     print(loss)\n",
    "# print (forces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for inputs, ts in htf.iter_from_trajectory(128, u,selection='resname PHE', r_cut=r_cut,period =20):\n",
    "#     forces,energy = model(inputs)\n",
    "#     aa_pos = inputs[1].astype('float32')\n",
    "#     box = inputs[2].astype('float32')\n",
    "#     box_size = [box[0,0],box[0,0],box[0,0]]\n",
    "# #     box_size = htf.box_size(box)\n",
    "#     mapped_pos = htf.center_of_mass(aa_pos, cg_mapping, box_size)\n",
    "#     # create the mapped neighbor list\n",
    "#     mapped_nlist = htf.compute_nlist(mapped_pos, r_cut, CG_NN, box_size, True)\n",
    "# #     mapped_forces = htf.compute_nlist_forces(mapped_nlist, energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class NlistNN(htf.SimModel):\n",
    "#     def setup(self, dim, top_neighs, cg_mapping, rcut, CG_NN):\n",
    "#         self.dense1 = tf.keras.layers.Layer(dim)\n",
    "#         self.dense2 = tf.keras.layers.Layer(dim)\n",
    "#         self.last = tf.keras.layers.Layer(1)\n",
    "#         self.top_neighs = top_neighs\n",
    "#         self.cg_mapping = cg_mapping\n",
    "#         self.CG_NN = CG_NN\n",
    "#         self.rcut = rcut\n",
    "\n",
    "#     def compute(self, nlist, positions, box, cg_mapping):\n",
    "#         # calculate the center of mass of a CG bead\n",
    "#         box_size = [box[0,0],box[0,0],box[0,0]]\n",
    "#         mapped_pos = htf.center_of_mass(positions[:,:3], self.cg_mapping, box_size)\n",
    "#         mapped_nlist = htf.compute_nlist(mapped_pos, self.rcut, self.CG_NN, box_size, True)\n",
    "# #         rinv_6 = htf.nlist_rinv(mapped_nlist)**6\n",
    "# #         # closest neighbors have largest value in 1/r, take top\n",
    "# #         top_n = tf.sort(rinv, axis=1, direction='DESCENDING')[\n",
    "# #             :, :self.top_neighs]\n",
    "# #         # run through NN\n",
    "# #         x = self.dense1(top_n)\n",
    "# #         x = self.dense2(x)\n",
    "#         def energy_lj(nlist):\n",
    "#             rinv_6 = htf.nlist_rinv(nlist)**6\n",
    "#             p_energy = 4.0 / 2.0 * (rinv_6 * rinv_6 - rinv_6)\n",
    "#             e = tf.reduce_sum(p_energy, axis=1)\n",
    "#             return e\n",
    "#         energy = energy_lj(nlist)\n",
    "#         # get per-particle energy\n",
    "#         mapped_energy =  energy_lj(mapped_nlist)\n",
    "#         forces = htf.compute_nlist_forces(nlist, energy)\n",
    "#         mapped_forces = htf.compute_nlist_forces(mapped_nlist, mapped_energy)\n",
    "#         nlist_grad = tf.gradients(energy, nlist)[0]\n",
    "# #         tf.print (mapped_nlist)\n",
    "# #         nlist_grad = tf.gradients(energy, mapped_nlist)[0]\n",
    "# #         mapped_forces = htf.compute_nlist_forces(mapped_nlist, energy)\n",
    "#         return forces[:,:3], energy, mapped_forces[:,:3], mapped_energy, mapped_pos, mapped_nlist   \n",
    "# model = NlistNN(128, dim=16, top_neighs=8, cg_mapping = cg_mapping, rcut = 10, CG_NN=max_neighbor_est )\n",
    "# model.compile('Adam', ['MeanSquaredError', None])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hoomd-tf2",
   "language": "python",
   "name": "hoomd-tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
